# ğŸ¤– PRITRAK AI Classification Engine: Complete Architecture Guide
**Version:** 1.0 (Production-Ready)  
**Date:** January 11, 2026  
**Purpose:** Implement enterprise-grade AI-assisted data classification on-premises  
**Integration Target:** DAP (Data Access Platform) DLP System  

---

## Table of Contents
1. [Executive Summary](#executive-summary)
2. [System Architecture](#system-architecture)
3. [AI Model Integration](#ai-model-integration)
4. [DLP Synchronization](#dlp-synchronization)
5. [Event Pipeline](#event-pipeline)
6. [Implementation Roadmap](#implementation-roadmap)

---

## Executive Summary

The PRITRAK AI Classification Engine enhances your DAP DLP system with intelligent, on-premises document classification using local language models (LLMs). This eliminates dependency on external APIs while maintaining enterprise security standards.

### Key Objectives
âœ… **On-Premises AI** - Run local models, zero data leaves your infrastructure  
âœ… **Real-Time Classification** - Classify files within 2-5 seconds  
âœ… **DLP Integration** - Classification results populate event logs automatically  
âœ… **Multi-Language Support** - English + French with extensible framework  
âœ… **Advanced Detection** - NIST/ISO-aligned classification hierarchy  

### Current State (DAP v1.0)
- âœ… File monitoring (create/rename/delete)
- âœ… Event logging with basic metadata
- âœ… Backend event storage (PostgreSQL/SQLite)
- âœ… WebSocket-based frontend updates
- âŒ **Classification layer (TO BE ADDED)**
- âŒ **AI model integration**
- âŒ **Advanced pattern matching**

---

## System Architecture

### High-Level Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRITRAK DLP SYSTEM                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚        FILE SYSTEM EVENT CAPTURE (Agent)             â”‚   â”‚
â”‚  â”‚  - Create, Rename, Delete Events                     â”‚   â”‚
â”‚  â”‚  - File Metadata Extraction                          â”‚   â”‚
â”‚  â”‚  - Path/Size/Extension Analysis                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                       â”‚                                      â”‚
â”‚                       â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      EVENT QUEUE & TRANSMISSION (WebSocket)          â”‚   â”‚
â”‚  â”‚  - Reliable event delivery to backend               â”‚   â”‚
â”‚  â”‚  - Connection pooling & retry logic                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                       â”‚                                      â”‚
â”‚                       â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   ğŸ†• CLASSIFICATION ENGINE (AI Pipeline)             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚ 1. Pre-Analysis (Lightweight)                â”‚   â”‚   â”‚
â”‚  â”‚  â”‚    - Size check, extension analysis          â”‚   â”‚   â”‚
â”‚  â”‚  â”‚    - Filename heuristics                     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚    - Quick win patterns                      â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚ 2. Content Retrieval & Parsing               â”‚   â”‚   â”‚
â”‚  â”‚  â”‚    - Fetch file content (first 5MB)          â”‚   â”‚   â”‚
â”‚  â”‚  â”‚    - Extract text from documents             â”‚   â”‚   â”‚
â”‚  â”‚  â”‚    - Language detection                      â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚ 3. Keyword/Pattern Matching                  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚    - Ruleset evaluation                      â”‚   â”‚   â”‚
â”‚  â”‚  â”‚    - Regex pattern detection                 â”‚   â”‚   â”‚
â”‚  â”‚  â”‚    - Context-aware scoring                   â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚ 4. AI Model Enhancement (Optional)           â”‚   â”‚   â”‚
â”‚  â”‚  â”‚    - LLM semantic analysis                   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚    - Confidence boosting                     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚    - False positive reduction                â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚ 5. Final Classification Decision             â”‚   â”‚   â”‚
â”‚  â”‚  â”‚    - Classification: PUBLIC/INTERNAL/...    â”‚   â”‚   â”‚
â”‚  â”‚  â”‚    - Confidence score (0-100%)               â”‚   â”‚   â”‚
â”‚  â”‚  â”‚    - Risk level assignment                   â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                      â”‚
â”‚                     â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  DATABASE STORAGE (Enriched Events)                  â”‚   â”‚
â”‚  â”‚  - Event ID, Timestamp, File Path                    â”‚   â”‚
â”‚  â”‚  - Classification, Confidence, Risk Level            â”‚   â”‚
â”‚  â”‚  - Keyword matches, Pattern detections               â”‚   â”‚
â”‚  â”‚  - Action taken (Allow/Warn/Block)                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                       â”‚                                      â”‚
â”‚                       â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  FRONTEND EVENT LOG VISUALIZATION                    â”‚   â”‚
â”‚  â”‚  - Real-time event dashboard                         â”‚   â”‚
â”‚  â”‚  - Classification filtering & search                 â”‚   â”‚
â”‚  â”‚  - Risk-based alerting & actions                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Breakdown

#### 1. **File System Agent** (Existing in DAP)
**Status:** âœ… Complete  
**Responsibility:** Capture file operations  
**Output:** File metadata + event details

```json
{
  "event_id": "evt-20260111-001",
  "timestamp": "2026-01-11T06:15:30Z",
  "event_type": "FILE_CREATED",
  "file_path": "C:\\Finance\\Q1_2026_Forecast.xlsx",
  "file_size": 125440,
  "file_extension": ".xlsx",
  "user": "john.doe",
  "device": "DESKTOP-ABC123"
}
```

#### 2. **Classification Engine** (ğŸ†• To Be Implemented)
**Responsibility:** Enrich events with classification data  
**Processing Time:** 2-5 seconds per file  
**Output:** Classification metadata

```json
{
  "classification": "CONFIDENTIAL",
  "risk_level": "HIGH",
  "confidence": 87.3,
  "detected_keywords": ["forecast", "financial", "Q1"],
  "pattern_matches": [],
  "justification": "Financial planning document with forecasted data",
  "processing_time_ms": 1240
}
```

#### 3. **Database Layer** (Extends Existing)
**Schema Update:** Add classification fields to events table

```sql
ALTER TABLE events ADD COLUMN (
  classification VARCHAR(50),
  confidence_score DECIMAL(5,2),
  risk_level VARCHAR(20),
  detected_keywords TEXT,
  processing_time_ms INTEGER
);
```

#### 4. **Frontend Integration** (Updates Existing UI)
**Enhancement:** Display classification in event log

```html
<!-- Event Row in Dashboard -->
<tr>
  <td>FILE_CREATED</td>
  <td>Q1_2026_Forecast.xlsx</td>
  <td><span class="badge badge-danger">CONFIDENTIAL</span></td>
  <td>87.3%</td>
  <td><span class="tag-high">HIGH</span></td>
</tr>
```

---

## AI Model Integration

### Option 1: Local LLM (Recommended for Security)

**Model:** Ollama + Mistral/Llama 2 (7B parameters)  
**Hardware Requirements:** 
- Minimum: 8GB VRAM GPU or 16GB RAM (CPU inference)
- Recommended: 12GB+ VRAM (inference time: <1 second)

**Workflow:**

```
FILE_EVENT â†’ PRE_ANALYSIS â†’ CONTENT_FETCH â†’ 
  LLM_PROMPT â†’ MODEL_INFERENCE â†’ POST_PROCESS â†’ 
  CLASSIFICATION_RESULT â†’ DATABASE_STORE â†’ UI_UPDATE
```

**Example LLM Prompt (Context-Aware):**

```
You are a data classification expert. Analyze the following document and classify it according to NIST security standards.

DOCUMENT METADATA:
- Filename: Q1_2026_Financial_Forecast.xlsx
- Size: 125KB
- File Type: Excel spreadsheet

DOCUMENT CONTENT (first 2000 chars):
[...document text...]

CLASSIFICATION CATEGORIES:
1. PUBLIC - No security risk
2. INTERNAL - Internal use only, limited disruption if exposed
3. CONFIDENTIAL - Restricted access, significant business impact
4. RESTRICTED - Trade secrets, critical PII, severe consequences

Respond in JSON format:
{
  "classification": "CATEGORY",
  "confidence": 0-100,
  "key_indicators": ["indicator1", "indicator2"],
  "justification": "brief explanation"
}
```

### Option 2: Hybrid Approach (Recommended for Production)

**Tier 1:** Lightweight pattern matching (95% accuracy, <100ms)  
**Tier 2:** LLM enhancement only for borderline cases (5-10% of files)  
**Benefits:** Ultra-fast classification + AI accuracy where needed

```
LIGHTWEIGHT_RULES (100ms)
    â†“
Confidence > 85%? â†’ RETURN RESULT
Confidence 50-85%? â†’ ESCALATE_TO_LLM (1-2 seconds)
    â†“
LLM_ANALYSIS
    â†“
FINAL_RESULT
```

---

## DLP Synchronization

### Event Flow Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  SYNCHRONIZATION PIPELINE                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  1. EVENT CAPTURE (Agent on Endpoint)                       â”‚
â”‚     â””â”€> FileSystemWatcher catches: CREATE, DELETE, MODIFY  â”‚
â”‚                                                               â”‚
â”‚  2. EVENT TRANSMISSION (WebSocket to Backend)               â”‚
â”‚     â””â”€> Reliable delivery with retry logic                  â”‚
â”‚         â””â”€> Queue management (in-memory + persistence)     â”‚
â”‚                                                               â”‚
â”‚  3. CLASSIFICATION REQUEST (Backend Queue Consumer)          â”‚
â”‚     â””â”€> Dequeue event                                        â”‚
â”‚     â””â”€> Check cache (identical files)                        â”‚
â”‚     â””â”€> Route to classification engine                       â”‚
â”‚                                                               â”‚
â”‚  4. CLASSIFICATION PROCESSING (Multi-stage Pipeline)         â”‚
â”‚     â”œâ”€> Stage 1: Pre-Analysis (extension, size, filename)  â”‚
â”‚     â”œâ”€> Stage 2: Content Parsing (extract text/metadata)   â”‚
â”‚     â”œâ”€> Stage 3: Pattern Matching (keywords + regex)        â”‚
â”‚     â”œâ”€> Stage 4: AI Enhancement (if confidence < 85%)      â”‚
â”‚     â””â”€> Stage 5: Decision (final classification)            â”‚
â”‚                                                               â”‚
â”‚  5. ENRICHMENT (Add Classification to Event)                â”‚
â”‚     â””â”€> {event + classification_result + metadata}          â”‚
â”‚                                                               â”‚
â”‚  6. STORAGE (Persist Enriched Event)                        â”‚
â”‚     â””â”€> Events table (PostgreSQL/SQLite)                    â”‚
â”‚     â””â”€> Update incident records if HIGH risk                â”‚
â”‚                                                               â”‚
â”‚  7. FRONTEND SYNC (WebSocket Broadcast)                     â”‚
â”‚     â””â”€> Notify connected dashboard clients                  â”‚
â”‚     â””â”€> Update in real-time with classification             â”‚
â”‚                                                               â”‚
â”‚  8. ACTION EXECUTION (Policy-Based Rules)                   â”‚
â”‚     â”œâ”€> RESTRICTED + Transfer attempt? â†’ BLOCK             â”‚
â”‚     â”œâ”€> CONFIDENTIAL + USB device? â†’ WARN + LOG            â”‚
â”‚     â”œâ”€> HIGH confidence match? â†’ ESCALATE to SOC           â”‚
â”‚     â””â”€> Store action in audit log                           â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Structures for Sync

**Event Record (After Classification):**

```go
type ClassifiedEvent struct {
    // Original event data
    EventID         string    `json:"event_id"`
    Timestamp       time.Time `json:"timestamp"`
    DeviceID        string    `json:"device_id"`
    FilePath        string    `json:"file_path"`
    FileSize        int64     `json:"file_size"`
    FileExtension   string    `json:"file_extension"`
    EventType       string    `json:"event_type"` // CREATE, DELETE, MODIFY
    
    // Classification data
    Classification  string    `json:"classification"` // PUBLIC, INTERNAL, CONFIDENTIAL, RESTRICTED
    ConfidenceScore float32   `json:"confidence_score"` // 0-100
    RiskLevel       string    `json:"risk_level"` // LOW, MEDIUM, HIGH, CRITICAL
    Justification   string    `json:"justification"`
    
    // Detection details
    DetectedKeywords []string `json:"detected_keywords"`
    PatternMatches   []string `json:"pattern_matches"`
    Language         string   `json:"language"` // "en", "fr"
    
    // Performance metrics
    ProcessingTimeMs int      `json:"processing_time_ms"`
    
    // Action taken
    Action          string    `json:"action"` // ALLOW, WARN, BLOCK
    ActionReason    string    `json:"action_reason"`
}
```

### Synchronization Guarantees

| Guarantee | Implementation |
|-----------|-----------------|
| **Ordering** | Process events in sequence per device |
| **Exactly-Once** | Idempotent classification + event deduplication |
| **Latency** | < 5 seconds end-to-end (including AI) |
| **Durability** | Persist event before UI update |
| **Consistency** | All replicas see same classification result |

---

## Event Pipeline

### Detailed Processing Stages

#### Stage 1: Pre-Analysis (Lightweight, <100ms)

```go
// File: backend/internal/classification/pre_analyzer.go
type PreAnalysisResult struct {
    Classification string  // Quick classification if evident
    QuickWin       bool    // true = don't need further analysis
    Confidence     float32
    Justification  string
}

func PreAnalyze(fileInfo *FileInfo) *PreAnalysisResult {
    // 1. Size check
    if fileInfo.Size == 0 || (fileInfo.Size < 100 && onlyWhitespace) {
        return &PreAnalysisResult{
            Classification: "PUBLIC",
            QuickWin: true,
            Confidence: 100,
            Justification: "Empty file",
        }
    }
    
    // 2. Extension check for known sensitive files
    sensitiveExts := []string{".key", ".pem", ".p12", ".pfx", ".db", ".sql"}
    if contains(sensitiveExts, fileInfo.Extension) && fileInfo.Size > 1024 {
        return &PreAnalysisResult{
            Classification: "RESTRICTED",
            QuickWin: true,
            Confidence: 95,
            Justification: fmt.Sprintf("Sensitive file type: %s", fileInfo.Extension),
        }
    }
    
    // 3. Filename analysis
    if contains(fileInfo.Name, []string{"password", "secret", "api_key"}) {
        return &PreAnalysisResult{
            Classification: "RESTRICTED",
            QuickWin: true,
            Confidence: 98,
            Justification: "Sensitive filename pattern detected",
        }
    }
    
    return nil // Continue to Stage 2
}
```

#### Stage 2: Content Parsing (1-2 seconds)

```go
// File: backend/internal/classification/content_parser.go
type ParsedContent struct {
    RawText      string
    Language     string   // "en", "fr", "mixed"
    WordCount    int
    KeyPhrases   []string
    Metadata     map[string]string
}

func ParseContent(filePath string, maxBytes int64) (*ParsedContent, error) {
    // 1. Read file (limit to 5MB to avoid memory issues)
    content, err := ioutil.ReadFile(filePath)
    if err != nil {
        return nil, err
    }
    
    if int64(len(content)) > maxBytes {
        content = content[:maxBytes]
    }
    
    // 2. Detect encoding and convert to UTF-8
    detected := chardet.NewTextDetector().DetectBest(content)
    
    // 3. Extract text based on file type
    var text string
    switch filepath.Ext(filePath) {
    case ".pdf":
        text, _ = extractPDF(content)
    case ".docx":
        text, _ = extractDOCX(content)
    case ".xlsx":
        text, _ = extractXLSX(content)
    default:
        text = string(content)
    }
    
    // 4. Language detection
    langDetector := whichlang.NewDetector()
    langs := langDetector.DetectLangs(text)
    lang := langs[0].Lang().String() // "en", "fr", etc.
    
    return &ParsedContent{
        RawText:    text,
        Language:   lang,
        WordCount:  len(strings.Fields(text)),
        KeyPhrases: extractKeyPhrases(text),
        Metadata:   extractMetadata(filePath),
    }, nil
}
```

#### Stage 3: Pattern Matching (1-2 seconds)

```go
// File: backend/internal/classification/matcher.go
type ScoringResult struct {
    ClassificationScores map[string]float32 // PUBLIC: 0.2, INTERNAL: 1.5, ...
    DetectedKeywords     []string
    RegexMatches         []RegexMatch
    ConfidenceBoost      float32
}

func MatchPatterns(content *ParsedContent) *ScoringResult {
    result := &ScoringResult{
        ClassificationScores: make(map[string]float32),
        DetectedKeywords:     []string{},
        RegexMatches:         []RegexMatch{},
    }
    
    // 1. Load keyword lists for detected language
    keywords := loadKeywords(content.Language)
    
    // 2. Scan for keywords with context
    for classification, kwList := range keywords {
        for _, kw := range kwList {
            matches := countKeywordOccurrences(content.RawText, kw)
            if matches > 0 {
                // Weight by classification importance
                weight := getKeywordWeight(classification)
                contextBoost := getContextBoost(content.RawText, kw)
                result.ClassificationScores[classification] += float32(matches) * weight * contextBoost
                result.DetectedKeywords = append(result.DetectedKeywords, kw)
            }
        }
    }
    
    // 3. Run regex patterns
    patterns := loadRegexPatterns() // Credit cards, SSNs, API keys, etc.
    for patternName, regex := range patterns {
        matches := regex.FindAllString(content.RawText, -1)
        if len(matches) > 0 {
            result.RegexMatches = append(result.RegexMatches, RegexMatch{
                Pattern: patternName,
                Count:   len(matches),
            })
            
            // Sensitive data detected = boost RESTRICTED score
            if isSensitivePattern(patternName) {
                result.ClassificationScores["RESTRICTED"] += 3.0 * float32(len(matches))
            }
        }
    }
    
    return result
}
```

#### Stage 4: AI Enhancement (Optional, 1-2 seconds)

```go
// File: backend/internal/classification/ai_enhancer.go
type AIEnhancementResult struct {
    Classification string
    Confidence     float32
    Reasoning      string
}

func EnhanceWithAI(content *ParsedContent, scoringResult *ScoringResult) (*AIEnhancementResult, error) {
    // Only call LLM if confidence < 85% (fast path for obvious cases)
    currentBest := findHighestScore(scoringResult.ClassificationScores)
    if currentBest.score > 85.0 {
        return nil // High confidence, skip LLM
    }
    
    // Build prompt
    prompt := buildClassificationPrompt(content, scoringResult)
    
    // Call local LLM (Ollama)
    client := ollama.NewClient("http://localhost:11434")
    response, err := client.Generate(context.Background(), &ollama.GenerateRequest{
        Model:  "mistral",
        Prompt: prompt,
        Stream: false,
    })
    if err != nil {
        // Fallback to rule-based if LLM fails
        return fallbackClassification(scoringResult), nil
    }
    
    // Parse LLM response
    result := parseAIResponse(response.Response)
    return result, nil
}
```

#### Stage 5: Final Decision (100ms)

```go
// File: backend/internal/classification/decision_engine.go
type FinalClassificationDecision struct {
    Classification string  // PUBLIC, INTERNAL, CONFIDENTIAL, RESTRICTED
    Confidence     float32 // 0-100
    RiskLevel      string  // LOW, MEDIUM, HIGH, CRITICAL
    Justification  string
}

func MakeDecision(context *ClassificationContext) *FinalClassificationDecision {
    // 1. Apply thresholds
    thresholds := map[string]float32{
        "RESTRICTED":   8.5,
        "CONFIDENTIAL": 5.5,
        "INTERNAL":     2.0,
        "PUBLIC":       0.5,
    }
    
    // 2. Find winning classification
    bestClass := ""
    bestScore := 0.0
    for class, score := range context.ScoringResult.ClassificationScores {
        if score > bestScore && score >= thresholds[class] {
            bestScore = score
            bestClass = class
        }
    }
    
    // 3. Handle edge cases
    if bestClass == "" {
        bestClass = "INTERNAL" // Conservative default
    }
    
    // 4. Calculate normalized confidence
    confidence := normalizeScore(bestScore, thresholds[bestClass]) * 100
    
    // 5. Map to risk level
    riskMap := map[string]string{
        "PUBLIC":       "LOW",
        "INTERNAL":     "LOW",
        "CONFIDENTIAL": "HIGH",
        "RESTRICTED":   "CRITICAL",
    }
    
    return &FinalClassificationDecision{
        Classification: bestClass,
        Confidence:     confidence,
        RiskLevel:      riskMap[bestClass],
        Justification:  buildJustification(context),
    }
}
```

---

## Implementation Roadmap

### Phase 1: Foundation (Weeks 1-2)
- [ ] Create classification module structure
- [ ] Implement pre-analysis engine
- [ ] Build content parser (text/PDF/Excel)
- [ ] Set up keyword/regex pattern database
- [ ] Integrate with existing event storage

### Phase 2: Core Classification (Weeks 3-4)
- [ ] Pattern matching engine
- [ ] Scoring algorithm
- [ ] Database schema updates
- [ ] Backend API endpoints for classification
- [ ] Unit tests (>85% coverage)

### Phase 3: AI Enhancement (Weeks 5-6)
- [ ] Ollama integration setup
- [ ] LLM model fine-tuning (optional)
- [ ] AI prompt engineering
- [ ] Fallback mechanisms
- [ ] Performance optimization

### Phase 4: Integration (Weeks 7-8)
- [ ] Event pipeline synchronization
- [ ] Frontend UI updates
- [ ] Real-time WebSocket updates
- [ ] Performance testing (2000+ files/hour)
- [ ] Security audit

### Phase 5: Production (Weeks 9-10)
- [ ] Load testing (100+ concurrent agents)
- [ ] Disaster recovery procedures
- [ ] Monitoring & alerting setup
- [ ] Documentation & training
- [ ] Beta testing with pilot users

---

## Next Steps

Continue reading in:
- **[02-IMPLEMENTATION.md](./02-IMPLEMENTATION.md)** - Detailed code implementation
- **[03-AI-SETUP.md](./03-AI-SETUP.md)** - LLM configuration and tuning
- **[04-INTEGRATION.md](./04-INTEGRATION.md)** - DLP synchronization details
- **[05-DEPLOYMENT.md](./05-DEPLOYMENT.md)** - Production deployment guide

---

**Last Updated:** January 11, 2026  
**Maintained By:** PRITRAK Security Team  
**Status:** ğŸŸ¢ Active Development

